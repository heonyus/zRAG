# Phase 1: Write Phase - Token-as-Document Learning
#
# 교수님 의도 (2=A):
# - z_i만 넣으면 해당 문서 D_i가 생성되도록 학습
# - LLM freeze, z_i + projection만 학습
#
# 성공 기준:
# - z_i만 넣었을 때 문서가 복원되는가?
# - Loss(NLL)가 충분히 낮아지는가?
#
# 사용법:
#   python training/train_write_phase.py --config configs/phase1_write.yaml
#   python training/train_write_phase.py --config configs/phase1_write.yaml --test

model:
  llm_name: "Qwen/Qwen3-8B"
  quantization: "4bit"

memory:
  m_tokens: 16          # Stage 3: 8→16 (용량 증가로 재구성 압력 강화)
  z_dim: 256            # 각 token의 벡터 차원

data:
  dataset: "hotpot_qa"
  save_dir: "./data/raw"
  num_docs: 200         # 스케일업: 200개
  max_doc_length: 512   # 문서 최대 토큰 수

training:
  # === Stage 3 설정 (용량+압력 강화) ===
  # 목표: z benefit vs random +0.42 → +0.5~0.6
  # 변경: m_tokens 16, epochs 50, lr_proj 보수적으로
  epochs_per_doc: 50    # Stage 3: 30→50 (학습 압력 증가)
  lr_z: 1e-3            # z_i learning rate (유지)
  lr_proj: 5e-5         # projection 학습 (1e-4→5e-5, 보수적으로 낮춤)
  weight_decay: 0.01
  use_amp: true         # Mixed precision
  early_stop_loss: 0.5  # 이 loss 이하면 early stop
  log_every: 5          # 자주 로깅

  # 안전장치
  collapse_threshold: 0.01    # z_std가 이 이하면 collapse 경고
  stagnation_patience: 10     # 10 epoch 동안 개선 없으면 경고 (5→10)
  checkpoint_every: 10        # 10 epoch마다 중간 저장

logging:
  project: "zrag-phase1"
  run_name: "write-phase-poc"
  save_dir: "./checkpoints/phase1_write"
  log_dir: "./logs/phase1_write"

# Phase 3에서 이 결과물 사용:
# - z_pool.pt: 학습된 z_i들 [num_docs, m_tokens, z_dim]
# - projection.pt: z_to_embedding layer weights

# GCP g2-standard-4 (L4 24GB) 기준:
# - num_docs=200: 충분히 가능
# - num_docs=500: 가능
# - num_docs=1000+: 가능 (Phase 1은 문서 하나씩 학습하므로)
#
# 주의: Phase 3 (Read)에서는 num_docs가 prefix 길이에 영향
# Phase 1에서는 num_docs가 "총 학습할 문서 수"일 뿐, 메모리 부담 없음
