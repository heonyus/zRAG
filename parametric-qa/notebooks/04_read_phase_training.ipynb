{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Read Phase Training\n",
    "\n",
    "Stage 2: Query → z_i selection → Answer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 로드\n",
    "config_path = PROJECT_ROOT / \"configs\" / \"phase1_poc.yaml\"\n",
    "with open(config_path) as f:\n",
    "    config = OmegaConf.create(yaml.safe_load(f))\n",
    "\n",
    "# Read phase config\n",
    "read_config = config.read_phase\n",
    "print(\"Read Phase Configuration:\")\n",
    "print(OmegaConf.to_yaml(read_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = read_config.batch_size\n",
    "LEARNING_RATE_Z = read_config.lr_z\n",
    "LEARNING_RATE_LORA = read_config.lr_lora\n",
    "NUM_EPOCHS = read_config.epochs\n",
    "TOP_K = read_config.top_k\n",
    "RETRIEVAL_WEIGHT = read_config.retrieval_weight\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Top-k: {TOP_K}\")\n",
    "print(f\"Retrieval weight: {RETRIEVAL_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import ReadPhaseDataset\n",
    "\n",
    "# 샘플 QA pairs\n",
    "sample_qa_pairs = [\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"answer\": \"Paris\",\n",
    "        \"gold_doc_ids\": [0],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who wrote Romeo and Juliet?\",\n",
    "        \"answer\": \"William Shakespeare\",\n",
    "        \"gold_doc_ids\": [1],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What did Albert Einstein develop?\",\n",
    "        \"answer\": \"the theory of relativity\",\n",
    "        \"gold_doc_ids\": [3],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model.llm_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Dataset\n",
    "read_dataset = ReadPhaseDataset(sample_qa_pairs, tokenizer)\n",
    "read_loader = DataLoader(read_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"QA pairs: {len(sample_qa_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read Phase Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadPhaseTrainer:\n",
    "    \"\"\"\n",
    "    Read Phase Training\n",
    "    \n",
    "    목표: max log P(answer | q, z_selected; θ)\n",
    "    \n",
    "    Loss = L_gen + λ * L_retrieval\n",
    "    - L_gen: answer generation loss (cross-entropy)\n",
    "    - L_retrieval: gold doc을 top-k에 포함하도록 하는 loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        lr_z: float = 1e-4,\n",
    "        lr_lora: float = 5e-5,\n",
    "        lr_selector: float = 1e-4,\n",
    "        retrieval_weight: float = 0.1,\n",
    "        top_k: int = 5,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # Optimizer 구성\n",
    "        param_groups = [\n",
    "            {\"params\": [model.doc_vectors], \"lr\": lr_z, \"name\": \"z\"},\n",
    "            {\"params\": model.z_to_embedding.parameters(), \"lr\": lr_lora, \"name\": \"projection\"},\n",
    "            {\"params\": model.selector.parameters(), \"lr\": lr_selector, \"name\": \"selector\"},\n",
    "            {\"params\": model.query_encoder.parameters(), \"lr\": lr_lora * 0.1, \"name\": \"query_encoder\"},\n",
    "        ]\n",
    "        \n",
    "        # LoRA params\n",
    "        lora_params = [p for n, p in model.llm.named_parameters() if \"lora\" in n.lower()]\n",
    "        param_groups.append({\"params\": lora_params, \"lr\": lr_lora, \"name\": \"lora\"})\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(param_groups)\n",
    "    \n",
    "    def compute_retrieval_loss(self, scores, gold_doc_ids):\n",
    "        \"\"\"\n",
    "        Retrieval loss: gold doc이 높은 score를 갖도록\n",
    "        \n",
    "        Args:\n",
    "            scores: [B, num_docs] - selection scores\n",
    "            gold_doc_ids: [B, num_gold] - gold document indices\n",
    "        \"\"\"\n",
    "        batch_size = scores.size(0)\n",
    "        num_docs = scores.size(1)\n",
    "        \n",
    "        # Gold mask 생성\n",
    "        gold_mask = torch.zeros_like(scores)  # [B, num_docs]\n",
    "        for i, gold_ids in enumerate(gold_doc_ids):\n",
    "            for gid in gold_ids:\n",
    "                if gid < num_docs:\n",
    "                    gold_mask[i, gid] = 1.0\n",
    "        \n",
    "        # Contrastive loss: gold docs vs non-gold docs\n",
    "        log_probs = F.log_softmax(scores, dim=-1)\n",
    "        \n",
    "        # Gold에 해당하는 log prob의 평균\n",
    "        gold_log_probs = (log_probs * gold_mask).sum(dim=-1)\n",
    "        num_gold = gold_mask.sum(dim=-1).clamp(min=1)\n",
    "        loss = -gold_log_probs / num_gold\n",
    "        \n",
    "        return loss.mean()\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"단일 training step\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        query_ids = batch[\"query_ids\"].to(self.device)\n",
    "        query_mask = batch[\"query_mask\"].to(self.device)\n",
    "        answer_ids = batch[\"answer_ids\"].to(self.device)\n",
    "        answer_mask = batch[\"answer_mask\"].to(self.device)\n",
    "        gold_doc_ids = batch[\"gold_doc_ids\"]  # list of tensors\n",
    "        \n",
    "        # Selection\n",
    "        selected_ids, scores = self.model.select_documents(\n",
    "            query_ids, query_mask, k=self.top_k\n",
    "        )\n",
    "        \n",
    "        # Generation loss\n",
    "        gen_loss = self.model(\n",
    "            query_ids=query_ids,\n",
    "            doc_indices=selected_ids,\n",
    "            answer_ids=answer_ids,\n",
    "            query_attention_mask=query_mask,\n",
    "            answer_attention_mask=answer_mask,\n",
    "        )\n",
    "        \n",
    "        # Retrieval loss\n",
    "        retrieval_loss = self.compute_retrieval_loss(scores, gold_doc_ids)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = gen_loss + self.retrieval_weight * retrieval_loss\n",
    "        \n",
    "        # Backward\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": loss.item(),\n",
    "            \"gen_loss\": gen_loss.item(),\n",
    "            \"retrieval_loss\": retrieval_loss.item(),\n",
    "        }\n",
    "    \n",
    "    def train_epoch(self, dataloader, epoch: int):\n",
    "        \"\"\"한 epoch 학습\"\"\"\n",
    "        total_loss = 0\n",
    "        total_gen_loss = 0\n",
    "        total_ret_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "        for batch in pbar:\n",
    "            losses = self.train_step(batch)\n",
    "            total_loss += losses[\"total_loss\"]\n",
    "            total_gen_loss += losses[\"gen_loss\"]\n",
    "            total_ret_loss += losses[\"retrieval_loss\"]\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({\n",
    "                \"total\": f\"{losses['total_loss']:.4f}\",\n",
    "                \"gen\": f\"{losses['gen_loss']:.4f}\",\n",
    "                \"ret\": f\"{losses['retrieval_loss']:.4f}\",\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss / max(num_batches, 1),\n",
    "            \"gen_loss\": total_gen_loss / max(num_batches, 1),\n",
    "            \"retrieval_loss\": total_ret_loss / max(num_batches, 1),\n",
    "        }\n",
    "\n",
    "print(\"ReadPhaseTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write phase checkpoint 로드 후 Read phase 학습\n",
    "# write_checkpoint = PROJECT_ROOT / \"checkpoints\" / \"phase1\" / \"write_final.pt\"\n",
    "\n",
    "# model = ParametricQA(...)\n",
    "# load_checkpoint(model, write_checkpoint)\n",
    "\n",
    "# trainer = ReadPhaseTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     lr_z=read_config.lr_z,\n",
    "#     lr_lora=read_config.lr_lora,\n",
    "#     retrieval_weight=RETRIEVAL_WEIGHT,\n",
    "#     top_k=TOP_K,\n",
    "#     device=device,\n",
    "# )\n",
    "\n",
    "# history = []\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     metrics = trainer.train_epoch(read_loader, epoch + 1)\n",
    "#     history.append(metrics)\n",
    "#     print(f\"Epoch {epoch + 1}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. QA 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import compute_em, compute_f1, compute_recall_at_k\n",
    "\n",
    "def evaluate_qa(model, qa_pairs, tokenizer, top_k=5, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    QA 성능 평가\n",
    "    \n",
    "    Metrics:\n",
    "    - EM (Exact Match)\n",
    "    - F1\n",
    "    - Recall@K (retrieval)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_em = []\n",
    "    all_f1 = []\n",
    "    all_recall = []\n",
    "    \n",
    "    for item in tqdm(qa_pairs, desc=\"Evaluating\"):\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"]\n",
    "        gold_doc_ids = item[\"gold_doc_ids\"]\n",
    "        \n",
    "        # Tokenize\n",
    "        q_encoded = tokenizer(\n",
    "            question, max_length=128, truncation=True,\n",
    "            padding=\"max_length\", return_tensors=\"pt\",\n",
    "        )\n",
    "        query_ids = q_encoded[\"input_ids\"].to(device)\n",
    "        query_mask = q_encoded[\"attention_mask\"].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Selection\n",
    "            selected_ids, scores = model.select_documents(query_ids, query_mask, k=top_k)\n",
    "            selected_list = selected_ids[0].cpu().tolist()\n",
    "            \n",
    "            # Generation\n",
    "            generated_ids = model.generate(\n",
    "                query_ids=query_ids,\n",
    "                doc_indices=selected_ids,\n",
    "                query_attention_mask=query_mask,\n",
    "                max_new_tokens=64,\n",
    "            )\n",
    "            prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Metrics\n",
    "        em = compute_em(prediction, answer)\n",
    "        f1 = compute_f1(prediction, answer)\n",
    "        recall = compute_recall_at_k(selected_list, gold_doc_ids, k=top_k)\n",
    "        \n",
    "        all_em.append(em)\n",
    "        all_f1.append(f1)\n",
    "        all_recall.append(recall)\n",
    "    \n",
    "    return {\n",
    "        \"EM\": sum(all_em) / len(all_em) * 100,\n",
    "        \"F1\": sum(all_f1) / len(all_f1) * 100,\n",
    "        f\"Recall@{top_k}\": sum(all_recall) / len(all_recall) * 100,\n",
    "    }\n",
    "\n",
    "# 평가 실행\n",
    "# metrics = evaluate_qa(model, sample_qa_pairs, tokenizer, top_k=TOP_K, device=device)\n",
    "# print(f\"Evaluation results: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예측 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(model, qa_pairs, tokenizer, top_k=5, device=\"cuda\", num_samples=5):\n",
    "    \"\"\"\n",
    "    예측 결과 상세 분석\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    for item in qa_pairs[:num_samples]:\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"]\n",
    "        gold_doc_ids = item[\"gold_doc_ids\"]\n",
    "        \n",
    "        # Tokenize\n",
    "        q_encoded = tokenizer(\n",
    "            question, max_length=128, truncation=True,\n",
    "            padding=\"max_length\", return_tensors=\"pt\",\n",
    "        )\n",
    "        query_ids = q_encoded[\"input_ids\"].to(device)\n",
    "        query_mask = q_encoded[\"attention_mask\"].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            selected_ids, scores = model.select_documents(query_ids, query_mask, k=top_k)\n",
    "            selected_list = selected_ids[0].cpu().tolist()\n",
    "            top_scores = scores[0].topk(top_k).values.cpu().tolist()\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                query_ids=query_ids,\n",
    "                doc_indices=selected_ids,\n",
    "                query_attention_mask=query_mask,\n",
    "                max_new_tokens=64,\n",
    "            )\n",
    "            prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"gold_answer\": answer,\n",
    "            \"prediction\": prediction,\n",
    "            \"gold_doc_ids\": gold_doc_ids,\n",
    "            \"selected_ids\": selected_list,\n",
    "            \"scores\": top_scores,\n",
    "            \"correct\": compute_em(prediction, answer) > 0,\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 분석 실행\n",
    "# results = analyze_predictions(model, sample_qa_pairs, tokenizer, top_k=TOP_K, device=device)\n",
    "# for r in results:\n",
    "#     print(f\"\\nQ: {r['question']}\")\n",
    "#     print(f\"A: {r['gold_answer']}\")\n",
    "#     print(f\"P: {r['prediction']}\")\n",
    "#     print(f\"Selected: {r['selected_ids']} (gold: {r['gold_doc_ids']})\")\n",
    "#     print(f\"Correct: {r['correct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Checkpoint 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_checkpoint(model, optimizer, epoch, metrics, save_path):\n",
    "    \"\"\"전체 체크포인트 저장 (Read phase 후)\"\"\"\n",
    "    save_path = Path(save_path)\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"metrics\": metrics,\n",
    "        \"doc_vectors\": model.doc_vectors.data.cpu(),\n",
    "        \"z_to_embedding_state_dict\": model.z_to_embedding.state_dict(),\n",
    "        \"selector_state_dict\": model.selector.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }\n",
    "    \n",
    "    # LoRA weights\n",
    "    model.llm.save_pretrained(save_path.parent / \"lora_weights\")\n",
    "    \n",
    "    # Query encoder\n",
    "    torch.save(\n",
    "        model.query_encoder.state_dict(),\n",
    "        save_path.parent / \"query_encoder.pt\"\n",
    "    )\n",
    "    \n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Full checkpoint saved to {save_path}\")\n",
    "\n",
    "# 저장\n",
    "# save_full_checkpoint(\n",
    "#     model, trainer.optimizer, NUM_EPOCHS, metrics,\n",
    "#     PROJECT_ROOT / \"checkpoints\" / \"phase1\" / \"read_final.pt\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
