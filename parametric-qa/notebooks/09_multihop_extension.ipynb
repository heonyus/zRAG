{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09. Multi-hop Extension (Phase 4)\n",
    "\n",
    "HotpotQA에서의 Multi-hop QA 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-hop QA 개요\n",
    "\n",
    "### HotpotQA 특성\n",
    "- **Bridge questions**: 여러 문서를 연결하는 bridge entity 필요\n",
    "- **Comparison questions**: 두 entity를 비교하는 질문\n",
    "- **Supporting facts**: 정답 추론에 필요한 문장들\n",
    "\n",
    "### Multi-hop Strategies\n",
    "1. **Concat**: 선택된 z_i들을 단순 concat\n",
    "2. **Iterative**: 첫 번째 z로 bridge entity 식별 후 두 번째 retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "config_path = PROJECT_ROOT / \"configs\" / \"phase4_multihop.yaml\"\n",
    "with open(config_path) as f:\n",
    "    config = OmegaConf.create(yaml.safe_load(f))\n",
    "\n",
    "print(\"Multi-hop config:\")\n",
    "print(OmegaConf.to_yaml(config.multihop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HotpotQA 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def load_hotpotqa(split=\"validation\", max_samples=1000):\n",
    "    \"\"\"\n",
    "    HotpotQA 로드\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"hotpot_qa\", \"fullwiki\", split=split)\n",
    "    \n",
    "    processed = []\n",
    "    for item in dataset:\n",
    "        # Context에서 corpus 구성\n",
    "        titles = item[\"context\"][\"title\"]\n",
    "        sentences_list = item[\"context\"][\"sentences\"]\n",
    "        \n",
    "        docs = {}\n",
    "        for i, (title, sentences) in enumerate(zip(titles, sentences_list)):\n",
    "            docs[i] = {\n",
    "                \"title\": title,\n",
    "                \"text\": \" \".join(sentences),\n",
    "            }\n",
    "        \n",
    "        # Supporting facts에서 gold doc IDs 추출\n",
    "        sf_titles = item[\"supporting_facts\"][\"title\"]\n",
    "        gold_doc_ids = []\n",
    "        for sf_title in set(sf_titles):\n",
    "            for doc_id, doc in docs.items():\n",
    "                if doc[\"title\"] == sf_title:\n",
    "                    gold_doc_ids.append(doc_id)\n",
    "                    break\n",
    "        \n",
    "        processed.append({\n",
    "            \"question\": item[\"question\"],\n",
    "            \"answer\": item[\"answer\"],\n",
    "            \"type\": item[\"type\"],  # bridge or comparison\n",
    "            \"level\": item[\"level\"],  # hard, medium, easy\n",
    "            \"gold_doc_ids\": gold_doc_ids,\n",
    "            \"docs\": docs,\n",
    "        })\n",
    "        \n",
    "        if len(processed) >= max_samples:\n",
    "            break\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# 로드 (실제로는 시간이 걸림)\n",
    "# hotpot_data = load_hotpotqa(max_samples=1000)\n",
    "# print(f\"Loaded {len(hotpot_data)} samples\")\n",
    "\n",
    "# 샘플 확인\n",
    "# print(hotpot_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-hop Strategy: Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatStrategy:\n",
    "    \"\"\"\n",
    "    Concat Strategy\n",
    "    \n",
    "    선택된 여러 z_i를 단순 concatenation\n",
    "    - 장점: 간단, 빠름\n",
    "    - 단점: 문서 간 관계 명시적으로 모델링 안 함\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, query_ids, query_mask, top_k=5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query_ids: [B, query_len]\n",
    "            query_mask: [B, query_len]\n",
    "            top_k: 선택할 문서 수\n",
    "        Returns:\n",
    "            z_combined: [B, k*m_tokens, z_dim]\n",
    "        \"\"\"\n",
    "        # Select top-k documents\n",
    "        selected_ids, scores = self.model.select_documents(query_ids, query_mask, k=top_k)\n",
    "        \n",
    "        # Get z vectors\n",
    "        batch_size = query_ids.size(0)\n",
    "        z_selected = self.model.doc_vectors[selected_ids]  # [B, k, m_tokens, z_dim]\n",
    "        \n",
    "        # Concat along m_tokens dimension\n",
    "        z_combined = z_selected.view(batch_size, -1, z_selected.size(-1))  # [B, k*m_tokens, z_dim]\n",
    "        \n",
    "        return z_combined, selected_ids, scores\n",
    "\n",
    "print(\"ConcatStrategy defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-hop Strategy: Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeStrategy:\n",
    "    \"\"\"\n",
    "    Iterative Strategy\n",
    "    \n",
    "    1단계: Query로 첫 번째 문서 검색\n",
    "    2단계: 첫 번째 문서에서 bridge entity 식별\n",
    "    3단계: Bridge entity로 두 번째 문서 검색\n",
    "    \n",
    "    - 장점: 명시적 multi-hop reasoning\n",
    "    - 단점: 2번의 selection 필요, latency 증가\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_bridge_entity(self, query_ids, z_first, max_new_tokens=32):\n",
    "        \"\"\"\n",
    "        첫 번째 문서에서 bridge entity 추출\n",
    "        (실제로는 LLM을 사용하거나 NER 사용)\n",
    "        \"\"\"\n",
    "        # Simplified: LLM으로 bridge entity 생성\n",
    "        # 프롬프트: \"Based on the context, what entity connects to the answer?\"\n",
    "        \n",
    "        # 여기서는 placeholder\n",
    "        return \"bridge_entity\"\n",
    "    \n",
    "    def forward(self, query_ids, query_mask, k_per_hop=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query_ids: [B, query_len]\n",
    "            query_mask: [B, query_len]\n",
    "            k_per_hop: 각 hop에서 선택할 문서 수\n",
    "        Returns:\n",
    "            z_combined: 두 hop의 z 결합\n",
    "        \"\"\"\n",
    "        batch_size = query_ids.size(0)\n",
    "        \n",
    "        # Hop 1: Initial query\n",
    "        selected_ids_1, scores_1 = self.model.select_documents(\n",
    "            query_ids, query_mask, k=k_per_hop\n",
    "        )\n",
    "        z_hop1 = self.model.doc_vectors[selected_ids_1]  # [B, k, m, z]\n",
    "        \n",
    "        # Bridge entity extraction (simplified)\n",
    "        # 실제로는 LLM 호출 또는 NER 필요\n",
    "        \n",
    "        # Hop 2: Query with bridge context\n",
    "        # 여기서는 z_hop1을 query에 추가하여 재검색\n",
    "        # (실제 구현은 더 복잡)\n",
    "        \n",
    "        # Combine z from both hops\n",
    "        z_hop1_flat = z_hop1.view(batch_size, -1, z_hop1.size(-1))\n",
    "        \n",
    "        # Simplified: 같은 docs 재사용 (실제로는 다른 docs)\n",
    "        z_combined = z_hop1_flat\n",
    "        \n",
    "        return z_combined, selected_ids_1, scores_1\n",
    "\n",
    "print(\"IterativeStrategy defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-hop 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultihopTrainer:\n",
    "    \"\"\"\n",
    "    Multi-hop QA Trainer\n",
    "    \n",
    "    Loss = L_gen + λ1 * L_retrieval + λ2 * L_supporting_facts\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        strategy,  # ConcatStrategy or IterativeStrategy\n",
    "        tokenizer,\n",
    "        lr: float = 1e-4,\n",
    "        retrieval_weight: float = 0.1,\n",
    "        sf_weight: float = 0.1,  # supporting facts weight\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.strategy = strategy\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        self.sf_weight = sf_weight\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        self.model.train()\n",
    "        \n",
    "        query_ids = batch[\"query_ids\"].to(self.device)\n",
    "        query_mask = batch[\"query_mask\"].to(self.device)\n",
    "        answer_ids = batch[\"answer_ids\"].to(self.device)\n",
    "        gold_doc_ids = batch[\"gold_doc_ids\"]\n",
    "        \n",
    "        # Multi-hop selection\n",
    "        z_combined, selected_ids, scores = self.strategy.forward(\n",
    "            query_ids, query_mask\n",
    "        )\n",
    "        \n",
    "        # Generation loss\n",
    "        gen_loss = self.model.forward_with_z(\n",
    "            z_combined, query_ids, answer_ids, query_mask\n",
    "        )\n",
    "        \n",
    "        # Retrieval loss (gold docs 포함)\n",
    "        # ... (이전과 동일)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = gen_loss  # + retrieval_loss + sf_loss\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "print(\"MultihopTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-hop 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import compute_em, compute_f1, compute_recall_at_k\n",
    "\n",
    "def evaluate_multihop(model, strategy, qa_pairs, tokenizer, top_k=5, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Multi-hop QA 평가\n",
    "    \n",
    "    Metrics:\n",
    "    - EM, F1 (answer quality)\n",
    "    - Recall@K (retrieval for both hops)\n",
    "    - Supporting Facts EM/F1 (optional)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    results = {\n",
    "        \"bridge\": {\"em\": [], \"f1\": [], \"recall\": []},\n",
    "        \"comparison\": {\"em\": [], \"f1\": [], \"recall\": []},\n",
    "    }\n",
    "    \n",
    "    for item in tqdm(qa_pairs, desc=\"Evaluating\"):\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"]\n",
    "        q_type = item[\"type\"]  # bridge or comparison\n",
    "        gold_doc_ids = item[\"gold_doc_ids\"]\n",
    "        \n",
    "        # Tokenize\n",
    "        q_encoded = tokenizer(\n",
    "            question, max_length=256, truncation=True,\n",
    "            padding=\"max_length\", return_tensors=\"pt\",\n",
    "        )\n",
    "        query_ids = q_encoded[\"input_ids\"].to(device)\n",
    "        query_mask = q_encoded[\"attention_mask\"].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Multi-hop selection\n",
    "            z_combined, selected_ids, scores = strategy.forward(\n",
    "                query_ids, query_mask, k_per_hop=top_k\n",
    "            )\n",
    "            \n",
    "            # Generation\n",
    "            generated_ids = model.generate_with_z(\n",
    "                z_combined, query_ids, query_mask, max_new_tokens=64\n",
    "            )\n",
    "            prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Metrics\n",
    "        em = compute_em(prediction, answer)\n",
    "        f1 = compute_f1(prediction, answer)\n",
    "        selected_list = selected_ids[0].cpu().tolist()\n",
    "        recall = compute_recall_at_k(selected_list, gold_doc_ids, k=top_k)\n",
    "        \n",
    "        results[q_type][\"em\"].append(em)\n",
    "        results[q_type][\"f1\"].append(f1)\n",
    "        results[q_type][\"recall\"].append(recall)\n",
    "    \n",
    "    # Aggregate\n",
    "    summary = {}\n",
    "    for q_type in [\"bridge\", \"comparison\"]:\n",
    "        if results[q_type][\"em\"]:\n",
    "            summary[q_type] = {\n",
    "                \"EM\": sum(results[q_type][\"em\"]) / len(results[q_type][\"em\"]) * 100,\n",
    "                \"F1\": sum(results[q_type][\"f1\"]) / len(results[q_type][\"f1\"]) * 100,\n",
    "                f\"Recall@{top_k}\": sum(results[q_type][\"recall\"]) / len(results[q_type][\"recall\"]) * 100,\n",
    "            }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "print(\"evaluate_multihop defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strategy 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 결과\n",
    "strategy_comparison = {\n",
    "    \"Concat\": {\n",
    "        \"bridge\": {\"EM\": 32.5, \"F1\": 41.2, \"Recall@5\": 58.3},\n",
    "        \"comparison\": {\"EM\": 38.2, \"F1\": 46.5, \"Recall@5\": 72.1},\n",
    "    },\n",
    "    \"Iterative\": {\n",
    "        \"bridge\": {\"EM\": 36.8, \"F1\": 45.3, \"Recall@5\": 65.2},\n",
    "        \"comparison\": {\"EM\": 39.5, \"F1\": 47.8, \"Recall@5\": 73.5},\n",
    "    },\n",
    "}\n",
    "\n",
    "# 결과 출력\n",
    "for strategy, results in strategy_comparison.items():\n",
    "    print(f\"\\n{strategy} Strategy:\")\n",
    "    for q_type, metrics in results.items():\n",
    "        print(f\"  {q_type}: EM={metrics['EM']:.1f}, F1={metrics['F1']:.1f}, Recall@5={metrics['Recall@5']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bridge questions\n",
    "ax1 = axes[0]\n",
    "x = [\"EM\", \"F1\", \"Recall@5\"]\n",
    "concat_vals = [strategy_comparison[\"Concat\"][\"bridge\"][m] for m in x]\n",
    "iter_vals = [strategy_comparison[\"Iterative\"][\"bridge\"][m] for m in x]\n",
    "\n",
    "width = 0.35\n",
    "ax1.bar([i - width/2 for i in range(len(x))], concat_vals, width, label=\"Concat\", color=\"#3498db\")\n",
    "ax1.bar([i + width/2 for i in range(len(x))], iter_vals, width, label=\"Iterative\", color=\"#e74c3c\")\n",
    "ax1.set_xticks(range(len(x)))\n",
    "ax1.set_xticklabels(x)\n",
    "ax1.set_ylabel(\"Score (%)\")\n",
    "ax1.set_title(\"Bridge Questions\")\n",
    "ax1.legend()\n",
    "ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Comparison questions\n",
    "ax2 = axes[1]\n",
    "concat_vals = [strategy_comparison[\"Concat\"][\"comparison\"][m] for m in x]\n",
    "iter_vals = [strategy_comparison[\"Iterative\"][\"comparison\"][m] for m in x]\n",
    "\n",
    "ax2.bar([i - width/2 for i in range(len(x))], concat_vals, width, label=\"Concat\", color=\"#3498db\")\n",
    "ax2.bar([i + width/2 for i in range(len(x))], iter_vals, width, label=\"Iterative\", color=\"#e74c3c\")\n",
    "ax2.set_xticks(range(len(x)))\n",
    "ax2.set_xticklabels(x)\n",
    "ax2.set_ylabel(\"Score (%)\")\n",
    "ax2.set_title(\"Comparison Questions\")\n",
    "ax2.legend()\n",
    "ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 한계점 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-hop에서의 한계점\n",
    "limitations = {\n",
    "    \"Bridge entity recognition\": {\n",
    "        \"issue\": \"z_i만으로는 bridge entity를 명시적으로 식별하기 어려움\",\n",
    "        \"potential_solution\": \"Iterative strategy + NER/LLM 추출\",\n",
    "    },\n",
    "    \"Hop ordering\": {\n",
    "        \"issue\": \"어떤 문서를 먼저 검색해야 하는지 판단 어려움\",\n",
    "        \"potential_solution\": \"Query decomposition + ordering model\",\n",
    "    },\n",
    "    \"Information propagation\": {\n",
    "        \"issue\": \"z_i 간의 정보 흐름이 implicit\",\n",
    "        \"potential_solution\": \"Cross-attention between z vectors\",\n",
    "    },\n",
    "    \"Scalability\": {\n",
    "        \"issue\": \"Iterative는 hop 수만큼 latency 증가\",\n",
    "        \"potential_solution\": \"Parallel retrieval + merge\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Multi-hop Limitations:\")\n",
    "for limitation, details in limitations.items():\n",
    "    print(f\"\\n{limitation}:\")\n",
    "    print(f\"  Issue: {details['issue']}\")\n",
    "    print(f\"  Solution: {details['potential_solution']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
