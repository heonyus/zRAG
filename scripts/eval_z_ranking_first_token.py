"""
Z Ranking Test (First-Token Only)
- teacher forcing ì—†ì´ ìˆœìˆ˜ first-token NLLë§Œìœ¼ë¡œ ranking
- doc_6 attractor í˜„ìƒì´ first-tokenì—ì„œë„ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸

ëª©ì : teacher forcing í¸í–¥ ì œê±° í›„ ìˆœìˆ˜ z conditioning í’ˆì§ˆ ì¸¡ì •
"""

import sys
sys.path.insert(0, "/home/lhe339/data/zRAG")

import torch
import torch.nn.functional as F
from torch.amp import autocast
from pathlib import Path
from omegaconf import OmegaConf
from datasets import load_dataset
from models.write_phase_model import WritePhaseModel, ZPoolManager
from training.train_write_phase import prepare_corpus


def compute_first_token_nll(model, z_i, doc_ids):
    """
    zë§Œìœ¼ë¡œ docì˜ ì²« ë²ˆì§¸ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” NLL ê³„ì‚°
    (teacher forcing ì—†ëŠ” pure z-only metric)
    """
    # zë¥¼ embedding spaceë¡œ projection
    alpha_clamped = torch.clamp(model.alpha, min=0.5)
    z_embed = alpha_clamped * model.z_to_embedding(z_i)  # [m_tokens, hidden]
    z_embed = z_embed.unsqueeze(0)  # [1, m_tokens, hidden]

    # z_embedë§Œ ì…ë ¥ìœ¼ë¡œ forward
    outputs = model.llm(
        inputs_embeds=z_embed,
        use_cache=False,
    )

    # ë§ˆì§€ë§‰ z í† í° ìœ„ì¹˜ì—ì„œ ì²« ë²ˆì§¸ doc í† í° ì˜ˆì¸¡
    last_logit = outputs.logits[0, -1, :]  # [vocab_size]
    first_doc_token = doc_ids[0, 0]  # scalar

    nll = F.cross_entropy(last_logit.unsqueeze(0), first_doc_token.unsqueeze(0))
    return nll.item()


def main():
    print("=" * 60)
    print("Z Ranking Test (FIRST-TOKEN ONLY)")
    print("=" * 60)
    print("ëª©ì : teacher forcing ì—†ì´ ìˆœìˆ˜ first-token NLLë¡œ ranking")
    print("      doc_6 attractorê°€ first-tokenì—ì„œë„ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸")

    # 1. Load config & model
    config_path = "/home/lhe339/data/zRAG/configs/phase1_write.yaml"
    config = OmegaConf.load(config_path)

    print("\n[1] Loading model...")
    model = WritePhaseModel(
        llm_name=config.model.llm_name,
        m_tokens=config.memory.m_tokens,
        z_dim=config.memory.z_dim,
        quantization=config.model.get("quantization", "4bit"),
    )

    # Load trained projection
    proj_path = Path(config.logging.save_dir) / "projection.pt"
    if proj_path.exists():
        model.load_projection(proj_path)
        print(f"  Loaded projection from {proj_path}")

    # Load z_pool
    z_pool_path = Path(config.logging.save_dir) / "z_pool.pt"
    z_pool = ZPoolManager(m_tokens=config.memory.m_tokens, z_dim=config.memory.z_dim)
    z_pool.load(z_pool_path)
    print(f"  Loaded z_pool: {len(z_pool.doc_ids)} documents")
    print(f"  Alpha value: {model.alpha.item():.4f}")

    # Load corpus
    dataset_name = config.data.get("dataset", "hotpot_qa")
    num_docs = config.data.get("num_docs", 10)
    print(f"  Loading dataset: {dataset_name}")
    dataset = load_dataset("hotpotqa/hotpot_qa", "fullwiki")
    corpus = prepare_corpus(dataset, max_docs=num_docs, dataset_name=dataset_name)

    # 2. Prepare test data
    print("\n[2] Preparing test data...")
    doc_ids_list = z_pool.doc_ids
    num_test_docs = len(doc_ids_list)

    tokenizer = model.tokenizer
    tokenized_docs = {}
    first_tokens = {}  # ê° ë¬¸ì„œì˜ ì²« í† í° ì €ì¥

    for doc_id in doc_ids_list:
        text = corpus[doc_id]
        encoded = tokenizer(
            text,
            return_tensors="pt",
            max_length=config.data.get("max_doc_length", 512),
            truncation=True,
            padding=False,
        )
        tokenized_docs[doc_id] = encoded["input_ids"].cuda()
        first_tokens[doc_id] = tokenizer.decode(encoded["input_ids"][0, 0])

    print(f"  Prepared {num_test_docs} documents")
    print(f"  Random baseline: {1/num_test_docs:.1%} (top-1)")

    # ê° ë¬¸ì„œì˜ ì²« í† í° ì¶œë ¥
    print(f"\n  --- First tokens of each document ---")
    for doc_id in doc_ids_list:
        first_tok = first_tokens[doc_id]
        print(f"    {doc_id}: '{first_tok}' (id={tokenized_docs[doc_id][0, 0].item()})")

    # 3. First-Token Ranking Test
    print("\n" + "=" * 60)
    print("[3] FIRST-TOKEN RANKING TEST")
    print("=" * 60)
    print("ê° z_iì— ëŒ€í•´ 10ê°œ ë¬¸ì„œì˜ first-token NLL ê³„ì‚° í›„ ranking")
    print("(pure z-only, NO teacher forcing)")

    model.eval()

    correct_top1 = 0
    correct_top3 = 0
    all_ranks = []
    nll_matrix = {}  # {(z_i, doc_j): nll}

    with torch.no_grad(), autocast('cuda', dtype=torch.bfloat16):
        for i, query_doc_id in enumerate(doc_ids_list):
            z_i = z_pool.get_z(query_doc_id).to(model.device)

            # ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ first-token NLL ê³„ì‚°
            nlls = {}
            for candidate_doc_id in doc_ids_list:
                doc_ids = tokenized_docs[candidate_doc_id]
                nll = compute_first_token_nll(model, z_i, doc_ids)
                nlls[candidate_doc_id] = nll
                nll_matrix[(query_doc_id, candidate_doc_id)] = nll

            # NLL ê¸°ì¤€ ì •ë ¬ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            sorted_docs = sorted(nlls.items(), key=lambda x: x[1])

            # ì •ë‹µ ë¬¸ì„œì˜ rank ì°¾ê¸°
            rank = -1
            for r, (doc_id, nll) in enumerate(sorted_docs):
                if doc_id == query_doc_id:
                    rank = r + 1
                    break

            all_ranks.append(rank)

            if rank == 1:
                correct_top1 += 1
                rank_symbol = "âœ“"
            elif rank <= 3:
                correct_top3 += 1
                rank_symbol = "â–³"
            else:
                rank_symbol = "âœ—"

            # ê²°ê³¼ ì¶œë ¥
            correct_nll = nlls[query_doc_id]
            best_nll = sorted_docs[0][1]
            best_doc = sorted_docs[0][0]
            nll_gap = correct_nll - best_nll

            print(f"\n  [{rank_symbol}] z_{i} ({query_doc_id}):")
            print(f"      rank = {rank}/{num_test_docs}")
            print(f"      correct doc first-token NLL = {correct_nll:.4f}")
            print(f"      best doc first-token NLL    = {best_nll:.4f} ({best_doc})")
            print(f"      gap (correct - best) = {nll_gap:+.4f}")

            # top-5 ranking
            top5_str = " > ".join([f"{d}({n:.2f})" for d, n in sorted_docs[:5]])
            print(f"      ranking: {top5_str}")

    # 4. Summary
    print("\n" + "=" * 60)
    print("[4] SUMMARY")
    print("=" * 60)

    top1_acc = correct_top1 / num_test_docs
    top3_acc = correct_top3 / num_test_docs
    avg_rank = sum(all_ranks) / len(all_ranks)
    random_top1 = 1 / num_test_docs
    random_top3 = min(3, num_test_docs) / num_test_docs
    random_avg_rank = (num_test_docs + 1) / 2

    print(f"  Total documents: {num_test_docs}")
    print(f"\n  {'Metric':<25} {'Actual':>10} {'Random':>10} {'Ratio':>10}")
    print(f"  {'-'*55}")
    print(f"  {'Top-1 Accuracy':<25} {top1_acc:>9.1%} {random_top1:>9.1%} {top1_acc/random_top1:>9.1f}x")
    print(f"  {'Top-3 Accuracy':<25} {top3_acc:>9.1%} {random_top3:>9.1%} {top3_acc/random_top3:>9.1f}x")
    print(f"  {'Average Rank':<25} {avg_rank:>10.2f} {random_avg_rank:>10.2f} {random_avg_rank/avg_rank:>9.1f}x")

    print(f"\n  â˜… Top-1 Accuracy: {top1_acc:.1%} ({correct_top1}/{num_test_docs})")
    print(f"\n  Rank distribution: {all_ranks}")

    # NLL í†µê³„
    print("\n  --- First-Token NLL Statistics ---")
    all_correct_nlls = []
    all_incorrect_nlls = []
    for query_doc_id in doc_ids_list:
        for candidate_doc_id in doc_ids_list:
            nll = nll_matrix[(query_doc_id, candidate_doc_id)]
            if query_doc_id == candidate_doc_id:
                all_correct_nlls.append(nll)
            else:
                all_incorrect_nlls.append(nll)

    avg_correct_nll = sum(all_correct_nlls) / len(all_correct_nlls)
    avg_incorrect_nll = sum(all_incorrect_nlls) / len(all_incorrect_nlls)
    nll_separation = avg_incorrect_nll - avg_correct_nll

    print(f"  avg first-token NLL (correct doc):   {avg_correct_nll:.4f}")
    print(f"  avg first-token NLL (incorrect doc): {avg_incorrect_nll:.4f}")
    print(f"  separation gap:                      {nll_separation:+.4f}")

    # 5. Doc Attractor ë¶„ì„
    print("\n" + "=" * 60)
    print("[5] DOC ATTRACTOR ANALYSIS")
    print("=" * 60)
    print("ì–´ë–¤ ë¬¸ì„œê°€ ê°€ì¥ ìì£¼ 'best doc'ìœ¼ë¡œ ì„ íƒë˜ëŠ”ì§€ ë¶„ì„")

    best_doc_counts = {}
    for query_doc_id in doc_ids_list:
        # ì´ zì—ì„œ best doc ì°¾ê¸°
        best_doc = min(doc_ids_list, key=lambda d: nll_matrix[(query_doc_id, d)])
        best_doc_counts[best_doc] = best_doc_counts.get(best_doc, 0) + 1

    print(f"\n  Best doc frequency:")
    for doc_id, count in sorted(best_doc_counts.items(), key=lambda x: -x[1]):
        pct = count / num_test_docs * 100
        bar = "â–ˆ" * count
        is_attractor = " â† ATTRACTOR!" if count > num_test_docs * 0.5 else ""
        print(f"    {doc_id}: {count:2d} ({pct:4.0f}%) {bar}{is_attractor}")

    # ë¬¸ì„œë³„ í‰ê·  NLL (ì–´ë–¤ zë¥¼ ë„£ë“  ì´ ë¬¸ì„œê°€ ì‰¬ìš´ì§€)
    print(f"\n  Average first-token NLL per document (across all z):")
    doc_avg_nlls = {}
    for candidate_doc_id in doc_ids_list:
        nlls_for_doc = [nll_matrix[(q, candidate_doc_id)] for q in doc_ids_list]
        doc_avg_nlls[candidate_doc_id] = sum(nlls_for_doc) / len(nlls_for_doc)

    for doc_id, avg_nll in sorted(doc_avg_nlls.items(), key=lambda x: x[1]):
        first_tok = first_tokens[doc_id]
        is_easy = " â† EASY DOC" if avg_nll == min(doc_avg_nlls.values()) else ""
        print(f"    {doc_id}: {avg_nll:.4f} (first='{first_tok}'){is_easy}")

    # 6. 10x10 NLL Matrix ì¶œë ¥
    print("\n" + "=" * 60)
    print("[6] NLL MATRIX (z_i row, doc_j col)")
    print("=" * 60)
    print("    ê° ì…€: NLL(doc_j | z_i)")
    print("    [X.X] = ëŒ€ê°ì„  (ì •ë‹µ)")
    print("    *X.X* = í•´ë‹¹ rowì—ì„œ ìµœì†Ÿê°’ (best)")

    # Header
    header = "         " + " ".join([f"d{d[-1]:>5}" for d in doc_ids_list])
    print(header)
    print("         " + "-" * (7 * num_test_docs))

    for query_doc_id in doc_ids_list:
        # ì´ rowì—ì„œ best doc ì°¾ê¸°
        best_in_row = min(doc_ids_list, key=lambda d: nll_matrix[(query_doc_id, d)])

        row = f"  z_{query_doc_id[-1]}  |"
        for candidate_doc_id in doc_ids_list:
            nll = nll_matrix[(query_doc_id, candidate_doc_id)]
            if query_doc_id == candidate_doc_id:
                row += f" [{nll:4.1f}]"  # ëŒ€ê°ì„  ê°•ì¡°
            elif candidate_doc_id == best_in_row:
                row += f" *{nll:4.1f}*"  # best ê°•ì¡°
            else:
                row += f"  {nll:4.1f} "
        print(row)

    # Row/Column í‰ê· 
    print("\n  --- Row/Column Averages ---")
    print("  (Row avg = í•´ë‹¹ zê°€ ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ë‚®ì€ NLLì„ ì£¼ëŠ”ì§€)")
    print("  (Col avg = í•´ë‹¹ ë¬¸ì„œê°€ ëª¨ë“  zì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ì‰¬ìš´ì§€)")

    row_avgs = {}
    col_avgs = {}
    for query_doc_id in doc_ids_list:
        row_avgs[query_doc_id] = sum(nll_matrix[(query_doc_id, d)] for d in doc_ids_list) / num_test_docs
    for candidate_doc_id in doc_ids_list:
        col_avgs[candidate_doc_id] = sum(nll_matrix[(q, candidate_doc_id)] for q in doc_ids_list) / num_test_docs

    print(f"\n  Row averages (z â†’ all docs):")
    for doc_id in sorted(row_avgs, key=row_avgs.get):
        print(f"    z_{doc_id[-1]}: {row_avgs[doc_id]:.4f}")

    print(f"\n  Column averages (all z â†’ doc):")
    for doc_id in sorted(col_avgs, key=col_avgs.get):
        is_easiest = " â† EASIEST" if doc_id == min(col_avgs, key=col_avgs.get) else ""
        print(f"    {doc_id}: {col_avgs[doc_id]:.4f}{is_easiest}")

    # 7. Diagnosis
    print("\n" + "=" * 60)
    print("[7] DIAGNOSIS")
    print("=" * 60)

    # Attractor ì¡´ì¬ ì—¬ë¶€
    max_attractor_count = max(best_doc_counts.values())
    attractor_doc = max(best_doc_counts, key=best_doc_counts.get)

    print(f"\n  [Attractor ë¶„ì„]")
    if max_attractor_count > num_test_docs * 0.5:
        print(f"  ğŸ”´ {attractor_doc}ê°€ {max_attractor_count}/{num_test_docs}íšŒ bestë¡œ ì„ íƒë¨")
        print(f"     â†’ ê°•í•œ attractor ì¡´ì¬ (z ë¶„í™” ì‹¤íŒ¨ ë˜ëŠ” ì‰¬ìš´ ë¬¸ì„œ)")

        # attractor docì˜ íŠ¹ì„± ë¶„ì„
        attractor_avg_nll = doc_avg_nlls[attractor_doc]
        other_avg_nll = sum(v for k, v in doc_avg_nlls.items() if k != attractor_doc) / (num_test_docs - 1)
        print(f"     {attractor_doc} avg NLL: {attractor_avg_nll:.4f}")
        print(f"     Other docs avg NLL: {other_avg_nll:.4f}")
        print(f"     Gap: {other_avg_nll - attractor_avg_nll:+.4f}")

        if attractor_avg_nll < other_avg_nll - 0.5:
            print(f"     â†’ {attractor_doc}ê°€ êµ¬ì¡°ì ìœ¼ë¡œ 'ì‰¬ìš´ ë¬¸ì„œ'ì„ (ì²« í† í°ì´ ì¼ë°˜ì )")
        else:
            print(f"     â†’ zë“¤ì´ ì¶©ë¶„íˆ ë¶„í™”ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±")
    else:
        print(f"  ğŸŸ¢ íŠ¹ì • ë¬¸ì„œë¡œì˜ ê°•í•œ attractor ì—†ìŒ")

    print(f"\n  [ë¶„ë¦¬ë ¥ ë¶„ì„]")
    if nll_separation > 1.0:
        print(f"  ğŸŸ¢ separation gap {nll_separation:.4f} - ì¢‹ì€ ë¶„ë¦¬ë ¥")
    elif nll_separation > 0.3:
        print(f"  ğŸŸ¡ separation gap {nll_separation:.4f} - ì•½í•œ ë¶„ë¦¬ë ¥")
    else:
        print(f"  ğŸ”´ separation gap {nll_separation:.4f} - ë¶„ë¦¬ë ¥ ê±°ì˜ ì—†ìŒ")

    print(f"\n  [ê²°ë¡ ]")
    if top1_acc >= 0.5 and nll_separation > 0.5:
        print("  â†’ first-tokenì—ì„œë„ ì–´ëŠ ì •ë„ ë¶„ë¦¬ë¨, objective ê°œì„ ìœ¼ë¡œ í–¥ìƒ ê°€ëŠ¥")
    elif top1_acc > random_top1:
        print("  â†’ zì— ì•½ê°„ì˜ ì •ë³´ ìˆìœ¼ë‚˜ ë¶„ë¦¬ ë¶€ì¡±")
        print("  â†’ z-only objective + contrastive loss í•„ìš”")
    else:
        print("  â†’ zê°€ ë¬¸ì„œ ë¶„ë¦¬ì— ì‹¤íŒ¨")
        print("  â†’ ê·¼ë³¸ì ì¸ objective ì¬ì„¤ê³„ í•„ìš”")

    # 8. ë¹„êµ (Teacher Forcing vs First-Token)
    print("\n" + "=" * 60)
    print("[8] COMPARISON: First-Token vs Teacher-Forcing")
    print("=" * 60)
    print("  ì´ì „ teacher-forcing(50í† í°) ê²°ê³¼ì™€ ë¹„êµ:")
    print("  (teacher-forcing ê²°ê³¼ëŠ” eval_z_ranking.pyì—ì„œ í™•ì¸)")
    print()
    print(f"  [First-Token Only (ì´ ìŠ¤í¬ë¦½íŠ¸)]")
    print(f"    Top-1 Accuracy:  {top1_acc:.1%}")
    print(f"    Top-3 Accuracy:  {top3_acc:.1%}")
    print(f"    Average Rank:    {avg_rank:.2f}")
    print(f"    NLL Separation:  {nll_separation:+.4f}")
    print()
    print("  [í•´ì„ ê°€ì´ë“œ]")
    print("  - First-Token ê²°ê³¼ê°€ Teacher-Forcingë³´ë‹¤ ë‚˜ì˜ë©´:")
    print("      â†’ zê°€ ìˆœìˆ˜ conditioningìœ¼ë¡œëŠ” ì•½í•¨")
    print("      â†’ teacher forcingì´ rankingì„ ë„ìš´ ê²ƒ")
    print("  - First-Token ê²°ê³¼ê°€ ë¹„ìŠ·í•˜ë©´:")
    print("      â†’ z ìì²´ì˜ conditioning í’ˆì§ˆ ë¬¸ì œ")
    print("  - doc_6 attractorê°€ first-tokenì—ì„œ ë” ê°•í•˜ë©´:")
    print("      â†’ doc_6ì˜ ì²« í† í°ì´ ëª¨ë¸ì˜ default outputê³¼ ê°€ê¹Œì›€")


if __name__ == "__main__":
    main()
