"""
Phase 1: Write Phase Training Script

êµìˆ˜ë‹˜ ì˜ë„ (2=A):
- z_ië§Œ ë„£ìœ¼ë©´ í•´ë‹¹ ë¬¸ì„œ D_iê°€ ìƒì„±ë˜ë„ë¡ í•™ìŠµ
- LLM freeze, z_i + projectionë§Œ í•™ìŠµ
- ë¬¸ì„œë³„ë¡œ z_ië¥¼ ìµœì í™”í•˜ê³ , ì „ì²´ z_poolë¡œ ì €ì¥

ì‚¬ìš©ë²•:
    python training/train_write_phase.py --config configs/phase1_write.yaml
    python training/train_write_phase.py --config configs/phase1_write.yaml --test       # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    python training/train_write_phase.py --config configs/phase1_write.yaml --eval_only  # í‰ê°€ë§Œ ì‹¤í–‰
"""

import sys
import logging
import argparse
from pathlib import Path
from tqdm import tqdm

import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.amp import autocast, GradScaler
import yaml
from omegaconf import OmegaConf

# Path setup
sys.path.append(str(Path(__file__).parent.parent))

from models.write_phase_model import WritePhaseModel, ZPoolManager
from data.download import download_dataset
from data.dataloader import WritePhaseDataset

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ê¸°ë³¸ ì½˜ì†” í•¸ë“¤ëŸ¬ (ê¸°ì¡´ ë°©ì‹)
if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    logger.addHandler(console_handler)


def setup_file_logging(log_dir: Path, run_name: str = None):
    """íŒŒì¼ ë¡œê¹… ì„¤ì •"""
    from datetime import datetime

    log_dir.mkdir(parents=True, exist_ok=True)

    # ì‹¤í–‰ ì´ë¦„ ìƒì„± (ì—†ìœ¼ë©´ íƒ€ì„ìŠ¤íƒ¬í”„)
    if run_name is None:
        run_name = datetime.now().strftime("%Y%m%d_%H%M%S")

    log_file = log_dir / f"train_{run_name}.log"

    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    logger.addHandler(file_handler)

    logger.info(f"ğŸ“ Log file: {log_file}")
    return log_file


def save_log_snapshot(log_file: Path, checkpoint_dir: Path, epoch: int):
    """ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œ ë¡œê·¸ ìŠ¤ëƒ…ìƒ·ë„ ì €ì¥"""
    import shutil
    if log_file and log_file.exists():
        snapshot_path = checkpoint_dir / f"log_epoch{epoch}.txt"
        shutil.copy(log_file, snapshot_path)
        logger.info(f"  ğŸ“ Log snapshot: {snapshot_path}")


def prepare_corpus(dataset, max_docs: int = 200, dataset_name: str = "hotpot_qa", corpus_path: str = None) -> dict:
    """
    ë°ì´í„°ì…‹ì—ì„œ corpus ì¶”ì¶œ ë˜ëŠ” pre-built corpus ë¡œë“œ

    Args:
        dataset: HuggingFace dataset (corpus_pathê°€ ì—†ì„ ë•Œ ì‚¬ìš©)
        max_docs: ìµœëŒ€ ë¬¸ì„œ ìˆ˜
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„ (hotpot_qa, natural_questions ë“±)
        corpus_path: pre-built corpus JSON íŒŒì¼ ê²½ë¡œ (corpus_builder.pyë¡œ ìƒì„±)

    Returns:
        corpus: {doc_id: doc_text} dict
    """
    # Pre-built corpus ë¡œë“œ (ìˆìœ¼ë©´)
    if corpus_path is not None:
        import json
        from pathlib import Path
        corpus_file = Path(corpus_path)
        if corpus_file.exists():
            logger.info(f"Loading pre-built corpus from: {corpus_path}")
            with open(corpus_file, "r", encoding="utf-8") as f:
                corpus = json.load(f)
            logger.info(f"  Loaded {len(corpus)} documents from pre-built corpus")
            # max_docs ì œí•œ ì ìš©
            if len(corpus) > max_docs:
                doc_ids = list(corpus.keys())[:max_docs]
                corpus = {k: corpus[k] for k in doc_ids}
                logger.info(f"  Trimmed to {len(corpus)} documents")
            return corpus
        else:
            logger.warning(f"corpus_path specified but not found: {corpus_path}")
            logger.warning("  Falling back to dataset extraction")

    corpus = {}

    # train split ì²˜ë¦¬
    if hasattr(dataset, "keys") and "train" in dataset.keys():
        data = dataset["train"]
    else:
        data = dataset

    for i, item in enumerate(data):
        if len(corpus) >= max_docs:
            break

        # HotpotQA format: context = {'title': [...], 'sentences': [[...], ...]}
        if dataset_name == "hotpot_qa" and "context" in item:
            ctx = item["context"]
            titles = ctx.get("title", [])
            sentences_list = ctx.get("sentences", [])

            # ê° ë¬¸ì„œ(title + sentences)ë¥¼ ë³„ë„ ë¬¸ì„œë¡œ ì¶”ì¶œ
            for title, sentences in zip(titles, sentences_list):
                if len(corpus) >= max_docs:
                    break
                doc_text = f"{title}\n" + " ".join(sentences)
                if len(doc_text) > 50:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì„œ ì œì™¸
                    doc_id = f"doc_{len(corpus)}"
                    corpus[doc_id] = doc_text

        # FlashRAG NQ format: retrieval_resultê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì´ ë¬¸ì„œ
        elif "retrieval_result" in item and item["retrieval_result"]:
            for j, doc in enumerate(item["retrieval_result"][:1]):  # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ
                doc_id = f"doc_{len(corpus)}"
                doc_text = doc.get("contents", doc.get("text", ""))
                if doc_text and len(doc_text) > 50:
                    corpus[doc_id] = doc_text

        # ì¼ë°˜ context (ë¬¸ìì—´)
        elif "context" in item and isinstance(item["context"], str):
            doc_id = f"doc_{len(corpus)}"
            doc_text = item["context"]
            if len(doc_text) > 50:
                corpus[doc_id] = doc_text

    logger.info(f"Extracted {len(corpus)} documents from dataset")
    return corpus


def train_single_document(
    model: WritePhaseModel,
    doc_id: str,
    doc_ids: torch.Tensor,
    doc_attention_mask: torch.Tensor,
    config: dict,
    scaler: GradScaler = None,
    enable_diagnostics: bool = True,
) -> tuple:
    """
    ë‹¨ì¼ ë¬¸ì„œì— ëŒ€í•´ z_ië¥¼ í•™ìŠµ

    Args:
        model: WritePhaseModel (LLM frozen)
        doc_id: ë¬¸ì„œ ID
        doc_ids: [1, doc_len] í† í°í™”ëœ ë¬¸ì„œ
        doc_attention_mask: [1, doc_len]
        config: í•™ìŠµ ì„¤ì •
        scaler: GradScaler for mixed precision
        enable_diagnostics: ì¤‘ê°„ ìƒ˜í”Œ ìƒì„± ë° í†µê³„ ì¶œë ¥ ì—¬ë¶€

    Returns:
        z_i: í•™ìŠµëœ z_i tensor
        final_loss: ìµœì¢… loss
    """
    # ìƒˆ z_i ìƒì„±
    z_i = model.create_z_for_doc()
    z_i_init = z_i.clone().detach()  # ì´ˆê¸°ê°’ ì €ì¥ (ë³€í™”ëŸ‰ ì¸¡ì •ìš©)

    # Learning rates from config
    lr_z = float(config.get("lr_z", 1e-2))
    lr_proj = float(config.get("lr_proj", 0))

    # Optimizer (z_i + projection if lr_proj > 0)
    optimizer = AdamW(
        model.get_trainable_params(z_i, lr_z=lr_z, lr_proj=lr_proj),
        weight_decay=config.get("weight_decay", 0.01),
    )

    # í•™ìŠµ ì„¤ì •
    epochs = config.get("epochs_per_doc", 100)
    log_every = config.get("log_every", 20)
    use_amp = config.get("use_amp", True)
    early_stop_loss = config.get("early_stop_loss", 0.5)

    best_loss = float("inf")
    best_z = z_i.clone().detach()

    # ì§„ë‹¨ìš©: ì¤‘ê°„ ìƒ˜í”Œ ìƒì„±í•  epochë“¤
    diagnostic_epochs = {0, 1, 5, 10, 20, 50, epochs - 1} if enable_diagnostics else set()

    # ì²« ë¬¸ì„œì˜ ì²« epochì—ì„œ ì´ˆê¸° ìƒíƒœ ë¡œê¹…
    if doc_id == "doc_0" and enable_diagnostics:
        stats = model.get_z_embed_stats(z_i)
        logger.info(f"  [{doc_id}] INIT: z_norm={stats['z_i_norm']:.4f}, "
                   f"z_embed_norm={stats['z_embed_norm']:.4f}, z_embed_std={stats['z_embed_std']:.4f}")

    for epoch in range(epochs):
        optimizer.zero_grad()

        if use_amp and scaler is not None:
            with autocast('cuda', dtype=torch.bfloat16):
                outputs = model(z_i, doc_ids, doc_attention_mask)
                loss = outputs["loss"]

            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)

            # Gradient norm ê³„ì‚° (z_ië§Œ)
            z_grad_norm = z_i.grad.norm().item() if z_i.grad is not None else 0.0

            nn.utils.clip_grad_norm_([z_i], 1.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(z_i, doc_ids, doc_attention_mask)
            loss = outputs["loss"]

            loss.backward()
            z_grad_norm = z_i.grad.norm().item() if z_i.grad is not None else 0.0
            nn.utils.clip_grad_norm_([z_i], 1.0)
            optimizer.step()

        loss_val = loss.item()

        # Best ì €ì¥
        if loss_val < best_loss:
            best_loss = loss_val
            best_z = z_i.clone().detach()

        # Early stopping
        if loss_val < early_stop_loss:
            logger.info(f"  [{doc_id}] Early stop at epoch {epoch}, loss={loss_val:.4f}")
            break

        # Logging (every log_every epochs)
        if epoch % log_every == 0 or epoch == epochs - 1:
            z_change = (z_i - z_i_init).norm().item()
            logger.debug(f"  [{doc_id}] Epoch {epoch}/{epochs}: loss={loss_val:.4f}, "
                        f"z_grad={z_grad_norm:.4f}, z_change={z_change:.4f}")

        # ì§„ë‹¨: ì¤‘ê°„ ìƒ˜í”Œ ìƒì„± ë° í†µê³„
        if epoch in diagnostic_epochs and enable_diagnostics:
            # z_embed í†µê³„ ì¶œë ¥
            stats = model.get_z_embed_stats(z_i)
            z_change = (z_i - z_i_init).norm().item()
            logger.info(f"  [{doc_id}] Epoch {epoch}: loss={loss_val:.4f} | "
                       f"z_norm={stats['z_i_norm']:.4f}, z_change={z_change:.4f}, "
                       f"z_grad={z_grad_norm:.4f} | "
                       f"z_embed_norm={stats['z_embed_norm']:.4f}, z_embed_std={stats['z_embed_std']:.4f}")

            # ì²« ë¬¸ì„œë§Œ ì¤‘ê°„ ìƒì„± í…ŒìŠ¤íŠ¸ (ì‹œê°„ ì ˆì•½)
            if doc_id == "doc_0":
                try:
                    sample = model.generate_from_z(z_i.detach(), max_new_tokens=50, do_sample=True)
                    logger.info(f"  [{doc_id}] Epoch {epoch} sample: {sample[:100]}...")
                except Exception as e:
                    logger.warning(f"  [{doc_id}] Epoch {epoch} generate failed: {e}")

    # ìµœì¢… ìƒíƒœ ë¡œê¹…
    final_z_change = (best_z - z_i_init).norm().item()
    logger.debug(f"  [{doc_id}] FINAL: best_loss={best_loss:.4f}, total_z_change={final_z_change:.4f}")

    return best_z, best_loss


def train_shuffled_documents(
    model: WritePhaseModel,
    tokenized_docs: dict,
    z_vectors: dict,
    config: dict,
    scaler: GradScaler = None,
    start_epoch: int = 0,
    log_file: Path = None,
) -> dict:
    """
    Shuffled doc training: projection drift ë°©ì§€ë¥¼ ìœ„í•´ ë¬¸ì„œë“¤ì„ ì„ì–´ì„œ í•™ìŠµ

    Args:
        start_epoch: resumeí•  ê²½ìš° ì‹œì‘ epoch (0ì´ë©´ ì²˜ìŒë¶€í„°)
        log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (ì²´í¬í¬ì¸íŠ¸ë§ˆë‹¤ ìŠ¤ëƒ…ìƒ· ì €ì¥)
    """
    import random
    import time
    import statistics

    # === Config ë¡œë“œ ===
    lr_z = float(config.get("lr_z", 1e-2))
    lr_proj = float(config.get("lr_proj", 1e-5))
    epochs = config.get("epochs_per_doc", 100)
    log_every = config.get("log_every", 20)
    use_amp = config.get("use_amp", True)
    early_stop_loss = config.get("early_stop_loss", 0.5)
    collapse_threshold = config.get("collapse_threshold", 0.01)
    stagnation_patience = config.get("stagnation_patience", 5)
    checkpoint_every = config.get("checkpoint_every", 10)

    doc_ids = list(tokenized_docs.keys())
    num_docs = len(doc_ids)
    remaining_epochs = epochs - start_epoch
    total_iters = num_docs * remaining_epochs

    # === í•™ìŠµ ì„¤ì • ì¶œë ¥ ===
    config_msg = f"""
{'=' * 70}
ğŸ“‹ TRAINING CONFIGURATION
{'=' * 70}
  Documents:     {num_docs}
  Epochs:        {epochs} (start={start_epoch}, remaining={remaining_epochs})
  Total iters:   {total_iters:,}
  lr_z:          {lr_z}
  lr_proj:       {lr_proj}
  use_amp:       {use_amp}
  log_every:     {log_every} epochs
  checkpoint:    every {checkpoint_every} epochs
{'=' * 70}
"""
    print(config_msg)
    logger.info(config_msg)

    # === Optimizer ì„¤ì • ===
    z_params = [z_vectors[doc_id] for doc_id in doc_ids]
    param_groups = [
        {"params": z_params, "lr": lr_z, "weight_decay": config.get("weight_decay", 0.01), "name": "z_vectors"},
        {"params": [model.alpha], "lr": lr_z, "weight_decay": 0.0, "name": "alpha"},
    ]

    if lr_proj > 0:
        param_groups.append({
            "params": model.z_to_embedding.parameters(),
            "lr": lr_proj,
            "weight_decay": 0.0,
            "name": "z_to_embedding"
        })
        print(f"ğŸ”§ Optimizer: z_lr={lr_z}, alpha_lr={lr_z}, proj_lr={lr_proj}")
    else:
        for param in model.z_to_embedding.parameters():
            param.requires_grad = False
        print(f"ğŸ”§ Optimizer: z_lr={lr_z}, alpha_lr={lr_z}, proj=FROZEN")

    optimizer = AdamW(param_groups, weight_decay=0.0)

    # === ìƒíƒœ ì¶”ì  ë³€ìˆ˜ ===
    best_losses = {doc_id: float("inf") for doc_id in doc_ids}
    current_losses = {doc_id: float("inf") for doc_id in doc_ids}
    z_init = {doc_id: z_vectors[doc_id].clone().detach() for doc_id in doc_ids}

    loss_history = []
    best_avg_loss = float("inf")
    stagnation_counter = 0
    collapse_warned = False

    # === ì´ˆê¸° z í†µê³„ ===
    init_z_norms = [z_vectors[d].norm().item() for d in doc_ids]
    init_z_stds = [z_vectors[d].std().item() for d in doc_ids]
    init_stats_msg = f"""
ğŸ“Š Initial z stats:
   z_norm: mean={statistics.mean(init_z_norms):.4f}, std={statistics.stdev(init_z_norms) if len(init_z_norms) > 1 else 0:.4f}
   z_std:  mean={statistics.mean(init_z_stds):.4f}
   alpha:  {model.alpha.item():.4f}"""
    print(init_stats_msg)
    logger.info(init_stats_msg)

    # === íƒ€ì´ë° ===
    start_time = time.time()
    epoch_times = []

    # === ë©”ì¸ í•™ìŠµ ë£¨í”„ ===
    print("\n" + "=" * 70)
    print("ğŸš€ TRAINING START")
    print("=" * 70)

    # ì „ì²´ ì§„í–‰ë¥  ë°”
    total_pbar = tqdm(
        total=total_iters,
        desc="Total",
        position=0,
        leave=True,
        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
    )

    global_iter = 0

    if start_epoch > 0:
        print(f"\nğŸ”„ RESUMING from epoch {start_epoch}")

    for epoch in range(start_epoch, epochs):
        epoch_start = time.time()
        random.shuffle(doc_ids)

        epoch_losses = []
        epoch_grad_norms = []

        # Epoch ì§„í–‰ë¥  ë°”
        epoch_pbar = tqdm(
            doc_ids,
            desc=f"Ep {epoch:03d}",
            position=1,
            leave=False,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}'
        )

        for doc_idx, doc_id in enumerate(epoch_pbar):
            optimizer.zero_grad()

            doc_data = tokenized_docs[doc_id]
            z_i = z_vectors[doc_id]

            # Forward + Backward
            if use_amp and scaler is not None:
                with autocast('cuda', dtype=torch.bfloat16):
                    outputs = model(z_i, doc_data["input_ids"], doc_data["attention_mask"])
                    loss = outputs["loss"]

                scaler.scale(loss).backward()
                scaler.unscale_(optimizer)
                grad_norm = nn.utils.clip_grad_norm_(z_params + list(model.z_to_embedding.parameters()), 1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(z_i, doc_data["input_ids"], doc_data["attention_mask"])
                loss = outputs["loss"]

                loss.backward()
                grad_norm = nn.utils.clip_grad_norm_(z_params + list(model.z_to_embedding.parameters()), 1.0)
                optimizer.step()

            # í†µê³„ ìˆ˜ì§‘
            loss_val = loss.item()
            grad_norm_val = grad_norm.item() if hasattr(grad_norm, 'item') else grad_norm
            epoch_losses.append(loss_val)
            epoch_grad_norms.append(grad_norm_val)
            current_losses[doc_id] = loss_val

            if loss_val < best_losses[doc_id]:
                best_losses[doc_id] = loss_val

            # Epoch ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸
            running_avg = sum(epoch_losses) / len(epoch_losses)
            epoch_pbar.set_postfix({
                'loss': f'{loss_val:.3f}',
                'avg': f'{running_avg:.3f}',
                'Î±': f'{model.alpha.item():.2f}'
            })

            # ì „ì²´ ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸
            global_iter += 1
            total_pbar.update(1)
            total_pbar.set_postfix({
                'ep': f'{epoch}/{epochs}',
                'loss': f'{running_avg:.3f}',
                'Î±': f'{model.alpha.item():.2f}'
            })

        epoch_pbar.close()

        # === Epoch í†µê³„ ê³„ì‚° ===
        epoch_time = time.time() - epoch_start
        epoch_times.append(epoch_time)

        avg_loss = statistics.mean(epoch_losses)
        loss_std = statistics.stdev(epoch_losses) if len(epoch_losses) > 1 else 0
        loss_min = min(epoch_losses)
        loss_max = max(epoch_losses)

        avg_grad = statistics.mean(epoch_grad_norms)

        # z í†µê³„
        z_norms = [z_vectors[d].norm().item() for d in doc_ids]
        z_stds = [z_vectors[d].std().item() for d in doc_ids]
        z_changes = [(z_vectors[d] - z_init[d]).norm().item() for d in doc_ids]

        avg_z_norm = statistics.mean(z_norms)
        avg_z_std = statistics.mean(z_stds)
        avg_z_change = statistics.mean(z_changes)

        loss_history.append(avg_loss)

        # === Epoch ë¡œê·¸ ì¶œë ¥ ===
        if epoch % log_every == 0 or epoch == epochs - 1 or epoch == start_epoch:
            elapsed = time.time() - start_time
            epochs_done = epoch - start_epoch + 1
            epochs_remaining = epochs - epoch - 1
            if epochs_done > 1:
                eta = (elapsed / epochs_done) * epochs_remaining
                eta_str = f"{int(eta // 60):02d}:{int(eta % 60):02d}"
            else:
                eta_str = "--:--"
            elapsed_str = f"{int(elapsed // 60):02d}:{int(elapsed % 60):02d}"

            epoch_log = f"""
{'â”€' * 70}
ğŸ“ˆ EPOCH {epoch:03d}/{epochs} | elapsed={elapsed_str} | ETA={eta_str} | {epoch_time:.1f}s/ep
{'â”€' * 70}
  Loss:  avg={avg_loss:.4f} | std={loss_std:.4f} | min={loss_min:.4f} | max={loss_max:.4f}
  Grad:  avg_norm={avg_grad:.4f}
  Alpha: {model.alpha.item():.4f}
  z:     norm={avg_z_norm:.4f} | std={avg_z_std:.4f} | Î”={avg_z_change:.4f}"""

            # ê°œì„  ìƒíƒœ
            if epoch > start_epoch:
                improvement = loss_history[-2] - avg_loss
                arrow = "â†“" if improvement > 0 else "â†‘" if improvement < 0 else "â†’"
                epoch_log += f"\n  Î”loss: {arrow} {abs(improvement):.4f} (prev={loss_history[-2]:.4f})"

            print(epoch_log)
            logger.info(epoch_log)

        # === ì•ˆì „ì¥ì¹˜ ì²´í¬ ===
        # 1. Collapse ê°ì§€
        if avg_z_std < collapse_threshold and not collapse_warned:
            print(f"\nâš ï¸  [COLLAPSE WARNING] z_std={avg_z_std:.6f} < {collapse_threshold}")
            print(f"    z vectorsê°€ ë„ˆë¬´ ë¹„ìŠ·í•´ì§€ê³  ìˆìŒ!")
            collapse_warned = True

        # 2. Stagnation ê°ì§€
        if avg_loss < best_avg_loss - 0.001:
            best_avg_loss = avg_loss
            stagnation_counter = 0
        else:
            stagnation_counter += 1
            if stagnation_counter >= stagnation_patience and stagnation_counter % stagnation_patience == 0:
                print(f"\nâš ï¸  [STAGNATION] {stagnation_counter} epochs without improvement")
                print(f"    best={best_avg_loss:.4f}, current={avg_loss:.4f}")

        # 3. ìƒ˜í”Œ ìƒì„± (íŠ¹ì • epochì—ì„œ)
        if epoch in {start_epoch, start_epoch + 1, 5, 10, epochs // 2, epochs - 1}:
            test_doc_id = doc_ids[0]
            try:
                with torch.no_grad():
                    sample = model.generate_from_z(
                        z_vectors[test_doc_id].detach(),
                        max_new_tokens=40,
                        do_sample=True
                    )
                print(f"  Sample: \"{sample[:80]}...\"")
            except Exception as e:
                print(f"  Sample: [failed: {e}]")

        # 4. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if checkpoint_every > 0 and (epoch + 1) % checkpoint_every == 0:
            checkpoint_dir = Path(config.get("save_dir", "./checkpoints/phase1_write"))
            checkpoint_dir.mkdir(parents=True, exist_ok=True)

            checkpoint_path = checkpoint_dir / f"z_pool_epoch{epoch+1}.pt"
            checkpoint_data = {
                "epoch": epoch + 1,
                "z_vectors": {doc_id: z_vectors[doc_id].detach().cpu() for doc_id in doc_ids},
                "avg_loss": avg_loss,
                "alpha": model.alpha.item(),
                "loss_history": loss_history,
                # projection layerë„ ì €ì¥ (resume ì‹œ í•„ìš”)
                "z_to_embedding": model.z_to_embedding.state_dict(),
            }
            torch.save(checkpoint_data, checkpoint_path)
            print(f"  ğŸ’¾ Checkpoint: {checkpoint_path}")

            # ë¡œê·¸ ìŠ¤ëƒ…ìƒ· ì €ì¥
            if log_file is not None:
                save_log_snapshot(log_file, checkpoint_dir, epoch + 1)

        # 5. Early stopping
        if avg_loss < early_stop_loss:
            print(f"\nâœ… Early stopping at epoch {epoch}, loss={avg_loss:.4f} < {early_stop_loss}")
            break

    total_pbar.close()

    # === ìµœì¢… ìš”ì•½ ===
    total_time = time.time() - start_time
    final_avg_loss = statistics.mean(list(best_losses.values()))

    summary_msg = f"""
{'=' * 70}
ğŸ TRAINING COMPLETED
{'=' * 70}
  Total time:    {int(total_time // 60)}m {int(total_time % 60)}s
  Epochs:        {start_epoch} â†’ {len(loss_history) + start_epoch} (ran {len(loss_history)}/{epochs - start_epoch})
  Final loss:    {loss_history[-1]:.4f}
  Best avg loss: {final_avg_loss:.4f}
  Final alpha:   {model.alpha.item():.4f}"""

    print(summary_msg)
    logger.info(summary_msg)

    # z ìµœì¢… í†µê³„
    final_z_norms = [z_vectors[d].norm().item() for d in doc_ids]
    final_z_stds = [z_vectors[d].std().item() for d in doc_ids]
    final_z_changes = [(z_vectors[d] - z_init[d]).norm().item() for d in doc_ids]

    z_stats_msg = f"""
  z final stats:
    norm:   {statistics.mean(final_z_norms):.4f} (init: {statistics.mean(init_z_norms):.4f})
    std:    {statistics.mean(final_z_stds):.4f} (init: {statistics.mean(init_z_stds):.4f})
    change: {statistics.mean(final_z_changes):.4f}"""
    print(z_stats_msg)
    logger.info(z_stats_msg)

    # Loss ë³€í™”
    if len(loss_history) > 1:
        loss_msg = f"""
  Loss trajectory: {loss_history[0]:.3f} â†’ {loss_history[-1]:.3f}
    Reduction: {loss_history[0] - loss_history[-1]:.3f} ({(1 - loss_history[-1]/loss_history[0])*100:.1f}%)"""
        print(loss_msg)
        logger.info(loss_msg)

    print("=" * 70 + "\n")
    logger.info("=" * 70)

    return best_losses


def run_write_phase_training(config_path: str = None, config: dict = None, test_mode: bool = False, eval_only: bool = False, resume: bool = False):
    """
    Phase 1: Write Phase ì „ì²´ í•™ìŠµ ì‹¤í–‰

    Args:
        config_path: YAML config íŒŒì¼ ê²½ë¡œ
        config: config dict (ì§ì ‘ ì „ë‹¬ ì‹œ)
        test_mode: Trueë©´ ì†Œê·œëª¨ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        eval_only: Trueë©´ í•™ìŠµ ìŠ¤í‚µí•˜ê³  ì €ì¥ëœ checkpointë¡œ í‰ê°€ë§Œ ì‹¤í–‰
        resume: Trueë©´ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ

    Returns:
        model: WritePhaseModel
        z_pool_manager: í•™ìŠµëœ z_ië“¤
        results: í•™ìŠµ ê²°ê³¼
    """
    # Load config
    if config is None:
        with open(config_path, "r") as f:
            config = OmegaConf.create(yaml.safe_load(f))

    # Test mode ì˜¤ë²„ë¼ì´ë“œ
    if test_mode:
        config.data.num_docs = 10
        config.training.epochs_per_doc = 20
        logger.info("=" * 60)
        logger.info("TEST MODE: num_docs=10, epochs_per_doc=20")
        logger.info("=" * 60)

    logger.info("=" * 60)
    logger.info("Phase 1: Write Phase Training (Token-as-Document)")
    logger.info("=" * 60)
    logger.info(f"Config:\n{OmegaConf.to_yaml(config)}")

    # ==========================================
    # 1. Data Preparation
    # ==========================================
    logger.info("\n[Step 1] Data Preparation")

    data_config = config.data
    raw_data = download_dataset(
        dataset_name=data_config.dataset,
        save_dir=data_config.get("save_dir", "./data/raw"),
    )

    # Corpus ì¶”ì¶œ (pre-built corpusê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©)
    corpus_path = data_config.get("corpus_path", None)
    corpus = prepare_corpus(
        raw_data,
        max_docs=data_config.num_docs,
        dataset_name=data_config.dataset,
        corpus_path=corpus_path,
    )
    logger.info(f"Corpus size: {len(corpus)} documents")

    if len(corpus) == 0:
        raise ValueError("No documents extracted from dataset!")

    # ==========================================
    # 2. Model Initialization
    # ==========================================
    logger.info("\n[Step 2] Model Initialization")

    model_config = config.model
    memory_config = config.memory

    model = WritePhaseModel(
        llm_name=model_config.llm_name,
        m_tokens=memory_config.m_tokens,
        z_dim=memory_config.z_dim,
        quantization=model_config.get("quantization", "4bit"),
    )

    # Z Pool Manager
    z_pool_manager = ZPoolManager(
        m_tokens=memory_config.m_tokens,
        z_dim=memory_config.z_dim,
    )

    # ==========================================
    # 3. Tokenize Documents
    # ==========================================
    logger.info("\n[Step 3] Tokenizing Documents")

    tokenizer = model.tokenizer
    max_doc_length = data_config.get("max_doc_length", 512)

    tokenized_docs = {}
    for doc_id, doc_text in tqdm(corpus.items(), desc="Tokenizing"):
        encoded = tokenizer(
            doc_text,
            max_length=max_doc_length,
            truncation=True,
            padding="max_length",
            return_tensors="pt",
        )
        tokenized_docs[doc_id] = {
            "input_ids": encoded["input_ids"].cuda(),
            "attention_mask": encoded["attention_mask"].cuda(),
        }

    logger.info(f"Tokenized {len(tokenized_docs)} documents")

    # ==========================================
    # 4. Training: Shuffled Document Training
    # ==========================================
    train_config = config.training
    use_amp = train_config.get("use_amp", True)

    save_dir = Path(config.logging.get("save_dir", "./checkpoints/phase1_write"))
    save_dir.mkdir(parents=True, exist_ok=True)

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    log_dir = save_dir / "logs"
    log_file = setup_file_logging(log_dir)

    doc_ids_list = list(tokenized_docs.keys())

    # Resume ëª¨ë“œ: ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
    start_epoch = 0
    resume_z_vectors = None
    resume_alpha = None
    resume_projection = None

    if resume:
        logger.info("\n[Step 3.5] RESUME MODE - Finding latest checkpoint")
        logger.info("=" * 60)

        # z_pool_epoch{N}.pt íŒŒì¼ë“¤ ì°¾ê¸°
        import re
        checkpoint_files = list(save_dir.glob("z_pool_epoch*.pt"))
        if not checkpoint_files:
            logger.warning("No checkpoint files found, starting from scratch")
            resume = False
        else:
            # ê°€ì¥ ë†’ì€ epoch ë²ˆí˜¸ ì°¾ê¸°
            epoch_pattern = re.compile(r"z_pool_epoch(\d+)\.pt")
            epochs_found = []
            for f in checkpoint_files:
                match = epoch_pattern.search(f.name)
                if match:
                    epochs_found.append((int(match.group(1)), f))

            if epochs_found:
                epochs_found.sort(key=lambda x: x[0], reverse=True)
                latest_epoch, latest_ckpt = epochs_found[0]
                logger.info(f"Found {len(epochs_found)} checkpoints, latest: epoch {latest_epoch}")

                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                ckpt = torch.load(latest_ckpt, map_location="cpu")
                start_epoch = ckpt["epoch"]
                resume_z_vectors = ckpt["z_vectors"]
                resume_alpha = ckpt.get("alpha", None)
                resume_projection = ckpt.get("z_to_embedding", None)

                logger.info(f"Resuming from epoch {start_epoch}")
                logger.info(f"  z_vectors: {len(resume_z_vectors)} documents")

                # z_vectors shape ê²€ì¦
                sample_z = list(resume_z_vectors.values())[0]
                expected_shape = (memory_config.m_tokens, memory_config.z_dim)
                if tuple(sample_z.shape) != expected_shape:
                    logger.error(f"  z_vectors shape mismatch!")
                    logger.error(f"    checkpoint: {tuple(sample_z.shape)}")
                    logger.error(f"    expected:   {expected_shape}")
                    logger.error(f"  Cannot resume - delete old checkpoints and restart")
                    raise ValueError(f"z_vectors shape mismatch: {tuple(sample_z.shape)} != {expected_shape}")
                logger.info(f"  z_vectors shape: {tuple(sample_z.shape)} âœ“")

                if resume_alpha is not None:
                    logger.info(f"  alpha: {resume_alpha:.4f}")
                if resume_projection is not None:
                    logger.info(f"  projection: found in checkpoint âœ“")
                else:
                    logger.warning(f"  projection: NOT found in checkpoint!")
                logger.info("=" * 60)
            else:
                logger.warning("No valid checkpoint files found, starting from scratch")
                resume = False

    if eval_only:
        # ==========================================
        # EVAL ONLY MODE: Load from checkpoint
        # ==========================================
        logger.info("\n[Step 4] EVAL ONLY MODE - Loading from checkpoint")
        logger.info("=" * 60)

        z_pool_path = save_dir / "z_pool.pt"
        proj_path = save_dir / "projection.pt"

        if not z_pool_path.exists():
            raise FileNotFoundError(f"z_pool not found: {z_pool_path}")
        if not proj_path.exists():
            raise FileNotFoundError(f"projection not found: {proj_path}")

        # Load z_pool
        logger.info(f"Loading z_pool from: {z_pool_path}")
        z_pool_manager.load(z_pool_path)

        # Load projection
        logger.info(f"Loading projection from: {proj_path}")
        model.load_projection(proj_path)

        # alpha fallback: epoch checkpointì—ì„œ ë¡œë“œ ì‹œë„
        if model.alpha.item() == 1.0:
            # projection.ptì— alpha ì—†ìŒ - epoch checkpointì—ì„œ ì°¾ê¸°
            epochs = config.training.get("epochs_per_doc", 30)
            epoch_ckpt_path = save_dir / f"z_pool_epoch{epochs}.pt"
            if epoch_ckpt_path.exists():
                epoch_ckpt = torch.load(epoch_ckpt_path, map_location="cpu")
                if "alpha" in epoch_ckpt:
                    loaded_alpha = epoch_ckpt["alpha"]
                    with torch.no_grad():
                        model.alpha.fill_(loaded_alpha)
                    logger.info(f"Loaded alpha={loaded_alpha:.4f} from epoch checkpoint")

                    # projection.ptë¥¼ ìƒˆ í¬ë§·(alpha í¬í•¨)ìœ¼ë¡œ ì¬ì €ì¥
                    model.save_projection(proj_path)
                    logger.info(f"Re-saved projection.pt with alpha={loaded_alpha:.4f}")

        z_pool_tensor = z_pool_manager.get_pool_tensor()
        logger.info(f"Loaded z_pool: shape={tuple(z_pool_tensor.shape)}")
        logger.info(f"Alpha after load: {model.alpha.item():.4f}")
        logger.info("=" * 60)

        # ê²°ê³¼ëŠ” ì €ì¥ëœ ê²ƒ ë¡œë“œ (ìˆìœ¼ë©´)
        results_path = save_dir / "results.pt"
        if results_path.exists():
            results = torch.load(results_path)
            logger.info(f"Loaded previous results: avg_loss={results.get('avg_loss', 'N/A')}")
        else:
            results = {
                "num_docs": len(corpus),
                "config": OmegaConf.to_container(config),
            }
    else:
        # ==========================================
        # TRAINING MODE
        # ==========================================
        logger.info("\n[Step 4] Training z_i with shuffled documents (drift ë°©ì§€)")

        scaler = GradScaler('cuda') if use_amp else None

        # Training config ë¡œê¹…
        lr_z = float(train_config.get("lr_z", 1e-2))
        lr_proj = float(train_config.get("lr_proj", 1e-5))
        epochs_per_doc = train_config.get("epochs_per_doc", 100)
        logger.info(f"Training config: lr_z={lr_z}, lr_proj={lr_proj}, epochs={epochs_per_doc}")
        logger.info(f"Projection: {'FROZEN' if lr_proj == 0 else f'learning (lr={lr_proj})'}")
        logger.info(f"Training mode: SHUFFLED (all docs trained together)")

        # ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ z_i ìƒì„± (ë˜ëŠ” resumeì—ì„œ ë¡œë“œ)
        z_vectors = {}
        if resume and resume_z_vectors is not None:
            logger.info(f"Loading {len(resume_z_vectors)} z_vectors from checkpoint")
            for doc_id in tqdm(doc_ids_list, desc="Loading z_i vectors"):
                if doc_id in resume_z_vectors:
                    z_vectors[doc_id] = resume_z_vectors[doc_id].to(model.device).requires_grad_(True)
                else:
                    logger.warning(f"  {doc_id} not in checkpoint, creating new")
                    z_vectors[doc_id] = model.create_z_for_doc()

            # alpha ë³µì›
            if resume_alpha is not None:
                with torch.no_grad():
                    model.alpha.fill_(resume_alpha)
                logger.info(f"Restored alpha: {model.alpha.item():.4f}")

            # projection layer ë³µì›
            if resume_projection is not None:
                model.z_to_embedding.load_state_dict(resume_projection)
                logger.info(f"Restored projection layer from checkpoint")
            else:
                logger.warning("Projection NOT restored - training from scratch projection!")
        else:
            for doc_id in tqdm(doc_ids_list, desc="Creating z_i vectors"):
                z_vectors[doc_id] = model.create_z_for_doc()
        logger.info(f"Prepared {len(z_vectors)} z_i vectors")

        # train_configì— save_dir ì¶”ê°€ (ì²´í¬í¬ì¸íŠ¸ìš©)
        train_config_dict = dict(train_config)
        train_config_dict["save_dir"] = str(save_dir)

        # Shuffled training ì‹¤í–‰
        losses = train_shuffled_documents(
            model=model,
            tokenized_docs=tokenized_docs,
            z_vectors=z_vectors,
            config=train_config_dict,
            scaler=scaler,
            start_epoch=start_epoch,
            log_file=log_file,
        )

        # ê²°ê³¼ ì €ì¥
        results = {
            "losses": losses,
            "num_docs": len(corpus),
            "config": OmegaConf.to_container(config),
        }

        # z_poolì— ì¶”ê°€
        for doc_id in tqdm(doc_ids_list, desc="Saving to z_pool"):
            z_pool_manager.add_z(doc_id, z_vectors[doc_id].detach())

    # ==========================================
    # 5. Final Save (skip if eval_only)
    # ==========================================
    if not eval_only:
        logger.info("\n[Step 5] Saving Results")

        # z_pool ì €ì¥ (Phase 3ì—ì„œ ë¡œë“œí•  ë©”ì¸ íŒŒì¼)
        z_pool_path = save_dir / "z_pool.pt"
        z_pool_manager.save(z_pool_path)

        # Projection layer ì €ì¥
        proj_path = save_dir / "projection.pt"
        model.save_projection(proj_path)

        # Results ì €ì¥
        results["avg_loss"] = sum(results["losses"].values()) / len(results["losses"])
        torch.save(results, save_dir / "results.pt")

        logger.info(f"\nFinal Average Loss: {results['avg_loss']:.4f}")
        logger.info(f"Saved z_pool to: {z_pool_path}")
        logger.info(f"Saved projection to: {proj_path}")

        # ==========================================
        # 5.1 Corpus Manifest ì €ì¥ (ë°ì´í„° ë™ì¼ì„± ê²€ì¦ìš©)
        # ==========================================
        import hashlib
        import json

        corpus_manifest = {
            "created_at": str(torch.cuda.current_device()) if torch.cuda.is_available() else "cpu",
            "num_docs": len(doc_ids_list),
            "documents": {}
        }

        for doc_id in tqdm(doc_ids_list, desc="Creating manifest"):
            text = corpus[doc_id]
            text_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()
            first_16_tokens = tokenized_docs[doc_id]["input_ids"][0, :16].tolist()

            corpus_manifest["documents"][doc_id] = {
                "text_sha256": text_hash,
                "text_len_chars": len(text),
                "first_16_tokens": first_16_tokens,
            }

        manifest_path = save_dir / "corpus_manifest.json"
        with open(manifest_path, "w") as f:
            json.dump(corpus_manifest, f, indent=2)
        logger.info(f"Saved corpus manifest to: {manifest_path}")
    else:
        logger.info("\n[Step 5] Skipping save (eval_only mode)")

    # ==========================================
    # 6. Validation: Document NLL Evaluation (í•µì‹¬ ì§€í‘œ)
    # ==========================================
    logger.info("\n[Step 6] Validation: Document NLL Evaluation")
    logger.info("=" * 60)
    logger.info("ëª©ì : z_iê°€ ì‹¤ì œë¡œ ë¬¸ì„œ contentë¥¼ ì¸ì½”ë”©í–ˆëŠ”ì§€ í™•ì¸")
    logger.info("ë°©ë²•: NLL(doc_i | z_i) vs NLL(doc_i | z_random) ë¹„êµ")
    logger.info("=" * 60)

    # Projection ìƒíƒœ í™•ì¸
    proj_frozen = not any(p.requires_grad for p in model.z_to_embedding.parameters())
    logger.info(f"\nProjection layer: {'FROZEN' if proj_frozen else 'TRAINABLE'}")
    logger.info(f"Final alpha value: {model.alpha.item():.4f}")

    # z_pool í†µê³„
    z_pool_tensor = z_pool_manager.get_pool_tensor()
    logger.info(f"z_pool shape: {z_pool_tensor.shape}")
    logger.info(f"z_pool stats: mean={z_pool_tensor.mean():.4f}, std={z_pool_tensor.std():.4f}")

    # Document NLL í‰ê°€ (ìƒ˜í”Œ 100ê°œë¡œ ì¦ê°€ - ì•ˆì •ì  í‰ê·  í™•ë³´)
    num_eval_samples = min(100, len(doc_ids_list))
    correct_nlls = []
    random_nlls = []
    wrong_nlls = []

    logger.info(f"\nğŸ“Š Document NLL Evaluation ({num_eval_samples} samples)")
    logger.info("-" * 60)

    # autocast context for evaluation (same as training)
    from contextlib import nullcontext
    amp_context = autocast('cuda', dtype=torch.bfloat16) if use_amp else nullcontext()

    model.eval()
    with torch.no_grad(), amp_context:
        for i in tqdm(range(num_eval_samples), desc="NLL Evaluation"):
            doc_id = doc_ids_list[i]
            doc_data = tokenized_docs[doc_id]

            # 1. NLL with correct z_i
            z_correct = z_pool_manager.get_z(doc_id).to(model.device)
            outputs_correct = model(z_correct, doc_data["input_ids"], doc_data["attention_mask"])
            nll_correct = outputs_correct["loss"].item()
            correct_nlls.append(nll_correct)

            # 2. NLL with random z (norm-matched for fair comparison)
            z_random_raw = torch.randn_like(z_correct)
            # correct zì™€ ë™ì¼í•œ normìœ¼ë¡œ ì •ê·œí™”
            z_random = z_random_raw * (z_correct.norm() / z_random_raw.norm())
            outputs_random = model(z_random, doc_data["input_ids"], doc_data["attention_mask"])
            nll_random = outputs_random["loss"].item()
            random_nlls.append(nll_random)

            # 3. NLL with wrong z (ë‹¤ë¥¸ ë¬¸ì„œì˜ z)
            wrong_idx = (i + num_eval_samples // 2) % len(doc_ids_list)
            wrong_doc_id = doc_ids_list[wrong_idx]
            z_wrong = z_pool_manager.get_z(wrong_doc_id).to(model.device)
            outputs_wrong = model(z_wrong, doc_data["input_ids"], doc_data["attention_mask"])
            nll_wrong = outputs_wrong["loss"].item()
            wrong_nlls.append(nll_wrong)

            logger.info(f"  {doc_id}: correct={nll_correct:.3f}, wrong={nll_wrong:.3f}, random={nll_random:.3f}")

    # í†µê³„ ê³„ì‚°
    import statistics
    avg_correct = statistics.mean(correct_nlls)
    avg_random = statistics.mean(random_nlls)
    avg_wrong = statistics.mean(wrong_nlls)

    std_correct = statistics.stdev(correct_nlls) if len(correct_nlls) > 1 else 0
    std_random = statistics.stdev(random_nlls) if len(random_nlls) > 1 else 0
    std_wrong = statistics.stdev(wrong_nlls) if len(wrong_nlls) > 1 else 0

    # z íš¨ê³¼ì„± ì§€í‘œ
    z_benefit_vs_random = avg_random - avg_correct
    z_benefit_vs_wrong = avg_wrong - avg_correct
    z_specificity = (sum(1 for c, w in zip(correct_nlls, wrong_nlls) if c < w) / num_eval_samples) * 100

    print("\n" + "=" * 60)
    print(f"ğŸ“ˆ DOCUMENT NLL RESULTS (n={num_eval_samples})")
    print("=" * 60)
    print(f"  avg NLL (correct z):  {avg_correct:.4f} Â± {std_correct:.4f}")
    print(f"  avg NLL (wrong z):    {avg_wrong:.4f} Â± {std_wrong:.4f}")
    print(f"  avg NLL (random z):   {avg_random:.4f} Â± {std_random:.4f}")
    print()
    print(f"  z benefit vs random:  {z_benefit_vs_random:+.4f} ({'âœ… GOOD' if z_benefit_vs_random > 0.5 else 'âš ï¸ WEAK' if z_benefit_vs_random > 0 else 'âŒ BAD'})")
    print(f"  z benefit vs wrong:   {z_benefit_vs_wrong:+.4f} ({'âœ… GOOD' if z_benefit_vs_wrong > 0.3 else 'âš ï¸ WEAK' if z_benefit_vs_wrong > 0 else 'âŒ BAD'})")
    print(f"  z specificity:        {z_specificity:.1f}% correct < wrong ({'âœ… GOOD' if z_specificity > 70 else 'âš ï¸ WEAK' if z_specificity > 50 else 'âŒ BAD'})")
    print("=" * 60)

    # ê²°ê³¼ ì €ì¥
    results["nll_correct"] = avg_correct
    results["nll_random"] = avg_random
    results["nll_wrong"] = avg_wrong
    results["z_benefit_vs_random"] = z_benefit_vs_random
    results["z_specificity"] = z_specificity

    # ê°„ë‹¨ ìƒì„± í…ŒìŠ¤íŠ¸ (ì°¸ê³ ìš©)
    logger.info("\nğŸ“ Sample Generation (ì°¸ê³ ìš©)")
    with amp_context:
        for i in range(min(2, len(doc_ids_list))):
            doc_id = doc_ids_list[i]
            z_i = z_pool_manager.get_z(doc_id).to(model.device)
            try:
                generated = model.generate_from_z(z_i, max_new_tokens=60, do_sample=False)
                original = corpus[doc_id][:100]
                logger.info(f"\n  [{doc_id}]")
                logger.info(f"    Original: {original}...")
                logger.info(f"    Generated: {generated[:100]}...")
            except Exception as e:
                logger.warning(f"  [{doc_id}] Generation failed: {e}")

    logger.info("\n" + "=" * 60)
    logger.info("Phase 1 Training Complete!")
    logger.info("=" * 60)

    return model, z_pool_manager, results


def main():
    """CLI entry point"""
    parser = argparse.ArgumentParser(description="Phase 1: Write Phase Training")
    parser.add_argument(
        "--config",
        type=str,
        default="configs/phase1_write.yaml",
        help="Path to config file",
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="Run in test mode (small scale)",
    )
    parser.add_argument(
        "--eval_only",
        action="store_true",
        help="Skip training, load checkpoint and run evaluation only",
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Resume training from latest checkpoint",
    )
    args = parser.parse_args()

    run_write_phase_training(
        config_path=args.config,
        test_mode=args.test,
        eval_only=args.eval_only,
        resume=args.resume
    )


if __name__ == "__main__":
    main()
